{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive text summarization \n",
    "    Personalised Text rank algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "def get_sentences(article):\n",
    "    extracts=sent_tokenize(article)\n",
    "    sentences=[]\n",
    "    for extract in extracts:\n",
    "        #print(extract)\n",
    "        clean_sentence=extract.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
    "        #print(clean_sentence)\n",
    "        obtained=word_tokenize(clean_sentence) \n",
    "        #print(obtained)\n",
    "        sentences.append(obtained)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster.util import cosine_distance\n",
    "def get_similarity(sent_1,sent_2,stop_words):\n",
    "  \n",
    "    sent_1=[w.lower() for w in sent_1]\n",
    "    sent_2=[w.lower() for w in sent_2]\n",
    "\n",
    "    total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
    "\n",
    "    vec_1= [0] * len(total)\n",
    "    vec_2= [0] * len(total)\n",
    "\n",
    "\n",
    "  ## Count Vectorization of two sentences\n",
    "    for w in sent_1:\n",
    "        if w not in stop_words:\n",
    "            vec_1[total.index(w)]+=1\n",
    "\n",
    "    for w in sent_2:\n",
    "        if w not in stop_words:\n",
    "            vec_2[total.index(w)]+=1\n",
    "\n",
    "\n",
    "    return 1-cosine_distance(vec_1,vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "def build_matrix(sentences):\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    sim_matrix=np.zeros((len(sentences),len(sentences)))\n",
    "    ## Adjacency matrix\n",
    "\n",
    "    for id1 in range(len(sentences)):\n",
    "        for id2 in range(len(sentences)):\n",
    "            if id1==id2:  #escaping diagonal elements\n",
    "                continue\n",
    "            else:\n",
    "                sim_matrix[id1][id2]=get_similarity(sentences[id1],sentences[id2],stop_words)\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(text, eps=0.000001, d=0.85):\n",
    "    score_mat = np.ones(len(text)) / len(text)\n",
    "    delta=1\n",
    "    ### iterative approach\n",
    "    while delta>eps:\n",
    "        score_mat_new = np.ones(len(text)) * (1 - d) / len(text) + d * text.T.dot(score_mat)\n",
    "        delta = abs(score_mat_new - score_mat).sum()\n",
    "        score_mat = score_mat_new\n",
    "\n",
    "    return score_mat_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer(article,req=3):\n",
    "    summarized=[]\n",
    "\n",
    "    sentence=get_sentences(article)\n",
    "\n",
    "    sim_matrix=build_matrix(sentence)\n",
    "\n",
    "    score=pagerank(sim_matrix)\n",
    "\n",
    "    ranked_sentence = sorted(((score[i],s) for i,s in enumerate(sentence)), reverse=True)\n",
    "    #print(ranked_sentence[2])\n",
    "  \n",
    "    for i in range(req):\n",
    "        #print(ranked_sentence[i][1])\n",
    "        summarized.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1908"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article='A black hole is a region of spacetime where gravity is so strong that nothing—no particles or even electromagnetic radiation such as light—can escape from it. The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole. The boundary of the region from which no escape is possible is called the event horizon. Although the event horizon has an enormous effect on the fate and circumstances of an object crossing it, according to general relativity it has no locally detectable features. In many ways, a black hole acts like an ideal black body, as it reflects no light. Moreover, quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation, with the same spectrum as a black body of a temperature inversely proportional to its mass. This temperature is on the order of billionths of a kelvin for black holes of stellar mass, making it essentially impossible to observe. Objects whose gravitational fields are too strong for light to escape were first considered in the 18th century by John Michell and Pierre-Simon Laplace. The first modern solution of general relativity that would characterize a black hole was found by Karl Schwarzschild in 1916, although its interpretation as a region of space from which nothing can escape was first published by David Finkelstein in 1958. Black holes were long considered a mathematical curiosity; it was not until the 1960s that theoretical work showed they were a generic prediction of general relativity. The discovery of neutron stars by Jocelyn Bell Burnell in 1967 sparked interest in gravitationally collapsed compact objects as a possible astrophysical reality. Black holes of stellar mass are expected to form when very massive stars collapse at the end of their life cycle. After a black hole has formed, it can continue to grow by absorbing mass from its surroundings.'\n",
    "len(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahp\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:38: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    }
   ],
   "source": [
    "Summary=summarizer(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole .', 'In many ways , a black hole acts like an ideal black body , as it reflects no light .', 'Moreover , quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation , with the same spectrum as a black body of a temperature inversely proportional to its mass .']\n"
     ]
    }
   ],
   "source": [
    "print(Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarization Using Spacy and PytextRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahp\\anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.4). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[black holes, Black holes, Black holes, A black hole, a black hole, a black hole, a black hole, a black hole]\n",
      "[stellar mass, stellar mass]\n",
      "[general relativity, general relativity, general relativity, general relativity]\n",
      "[event horizons, the event horizon, the event horizon]\n",
      "[mass, its mass]\n",
      "[Jocelyn Bell Burnell, Jocelyn Bell Burnell]\n",
      "[neutron stars]\n",
      "[Hawking radiation]\n",
      "[theoretical work]\n",
      "[spacetime]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "doc = nlp(article)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "for p in doc._.phrases[0:10]:\n",
    "    \n",
    "    print(p.chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
